{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37509057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db03ed",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bb951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 1280\n",
    "img_height = 720\n",
    "\n",
    "class_names = ['Accident', 'NonAccident']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ea1de",
   "metadata": {},
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0b4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model/modelx_GT_1280x720_best.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f363d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, img_height, img_width):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d068599",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_indonesia/tertibnya-pengendara-di-surabaya-setelah-ada-cctv_20170904_223346.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_indonesia/tertibnya-pengendara-di-surabaya-setelah-ada-cctv_20170904_223346.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path, img_height, img_width)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, img_height, img_width):\n\u001b[1;32m----> 2\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(image)\n\u001b[0;32m      4\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_indonesia/tertibnya-pengendara-di-surabaya-setelah-ada-cctv_20170904_223346.jpg'"
     ]
    }
   ],
   "source": [
    "image = preprocess_image('test_indonesia/tertibnya-pengendara-di-surabaya-setelah-ada-cctv_20170904_223346.jpg', img_height, img_width)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(image, verbose=0)\n",
    "print(predictions)\n",
    "predicted_class = np.argmax(predictions)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d75d4",
   "metadata": {},
   "source": [
    "#### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b722284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    \n",
    "    image = np.expand_dims(img, axis=0)\n",
    "    prediction=model.predict(image)[0]\n",
    "    \n",
    "    return {class_names[i]: float(prediction[i]) for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\ASUS\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\gradio\\outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\ASUS\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `capture_session` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n"
     ]
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(img_width, img_height))\n",
    "label = gr.outputs.Label(num_top_classes=2)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label, capture_session=True).launch(debug='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378457d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
